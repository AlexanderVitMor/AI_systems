{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:28:10.441455Z",
     "start_time": "2024-11-04T15:28:10.438312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras.src.callbacks as cb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "1716f0b7c9cf7882",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T14:45:15.221966Z",
     "start_time": "2024-11-04T14:45:15.217406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция генерации датасета для логического выражения (a xor b) и (b xor c)\n",
    "def generate_dataset(size: int=100) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for classification.\n",
    "\n",
    "    Args:\n",
    "        size (int): The number of samples in the dataset. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "         tuple[np.ndarray, np.ndarray]: A tuple containing the feature matrix X and the target vector y.\n",
    "            X is a 2D array where each row represents a sample and each column represents a feature.\n",
    "            y is a 1D array where each element represents the class label of the corresponding sample.\n",
    "\n",
    "    Examples:\n",
    "        >>> X, y = generate_dataset(10)\n",
    "        >>> print(X)\n",
    "        [[0 0 0]\n",
    "         [0 0 1]\n",
    "         ...,\n",
    "          [1 0 1],\n",
    "          [0 1 0]]\n",
    "        >>> print(y)\n",
    "        [0 1 0 ..., 1 0 1]\n",
    "    \"\"\"\n",
    "    X: np.ndarray = np.random.randint(0, 2, size=(size, 3))\n",
    "    y: np.ndarray = np.logical_and(np.logical_not(X[:, 0] == X[:, 1]), np.logical_not(X[:, 1] == X[:, 2])).astype(int)\n",
    "    return X, y"
   ],
   "id": "36ed3824f0ea328",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:52:05.691249Z",
     "start_time": "2024-11-04T15:52:05.686733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция создания модели нейронной сети\n",
    "def create_model() -> Sequential:\n",
    "    \"\"\"\n",
    "    Creates a neural network model for binary classification.\n",
    "\n",
    "    The model consists of 3 dense layers with ReLU activation function\n",
    "    and sigmoid activation function in the output layer. It is compiled\n",
    "    with binary cross-entropy loss, Adam optimizer and accuracy metric.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Sequential: A compiled Keras neural network model for binary classification.\n",
    "\n",
    "    Examples:\n",
    "        >>> from tensorflow.keras.models import Sequential\n",
    "        >>> baseline_model = create_model()\n",
    "        >>> print(baseline_model.summary())\n",
    "    \"\"\"\n",
    "    baseline_model: Sequential = Sequential()\n",
    "    baseline_model.add(Input(shape=(3,), name='input'))\n",
    "    baseline_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    baseline_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    baseline_model.summary()\n",
    "    return baseline_model"
   ],
   "id": "10295e7ef987b309",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:53:01.951280Z",
     "start_time": "2024-11-04T15:53:01.945873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_error_report(model_report: Sequential, val_split: float=0.2):\n",
    "    data: pd.DataFrame = pd.read_csv('data/data_bin.csv')\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    history: cb.History = model_report.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=val_split)\n",
    "    history_df: pd.DataFrame = pd.DataFrame(history.history)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15,7))\n",
    "\n",
    "    sns.lineplot(data=history_df['accuracy'], ax=axes[0])\n",
    "    axes[0].set_title('val_ccuracy')\n",
    "\n",
    "    sns.lineplot(data=history_df['loss'], ax=axes[1])\n",
    "    axes[1].set_title('val_loss')\n",
    "\n",
    "    model_report.evaluate(X_test, y_test)\n",
    "    \n",
    "    return model_report"
   ],
   "id": "9e2a495e8fc45a3d",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:47:54.848269Z",
     "start_time": "2024-11-04T15:47:54.767888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simulate_neural_layer(data_tensor, weight_tensor):\n",
    "    \"\"\"\n",
    "    Simulates the behavior of a neural layer.\n",
    "    \n",
    "    Args:\n",
    "        data_tensor: Input tensor with shape (5, 3)\n",
    "        weight_tensor: Weight tensor\n",
    "        \n",
    "    Returns:\n",
    "        Output tensor after applying the neural layer\n",
    "    \"\"\"\n",
    "\n",
    "    # Тензор весов имеет размерность (3, n), где n - количество нейронов в слое\n",
    "    num_neurons = weight_tensor.shape[-1]\n",
    "\n",
    "    # Инициализируем output tensor с нулями по размеру 5 x n\n",
    "    output_tensor = np.zeros((5, num_neurons))\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(num_neurons):\n",
    "            # Для каждого нейрона в слое вычисляем выход на основе входного тензора и веса\n",
    "            output_tensor[i, j] += data_tensor[i, 0] * weight_tensor[0, j]\n",
    "            output_tensor[i, j] += data_tensor[i, 1] * weight_tensor[1, j]\n",
    "            output_tensor[i, j] += data_tensor[i, 2] * weight_tensor[2, j]\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "# Инициализация входных данных и весов\n",
    "data_tensor = tf.random.uniform((5, 3))\n",
    "weight_tensor = tf.random.uniform((3, 10))\n",
    "\n",
    "# Симуляция поведения нейронного слоя\n",
    "output_tensor = simulate_neural_layer(data_tensor, weight_tensor)\n",
    "\n",
    "print(\"Входные данные:\")\n",
    "print(data_tensor)\n",
    "print(\"\\nТензор весов:\")\n",
    "print(weight_tensor)\n",
    "print(\"\\nВыход после симуляции:\")\n",
    "print(output_tensor)"
   ],
   "id": "19533f6533817913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные:\n",
      "tf.Tensor(\n",
      "[[0.44240892 0.8645688  0.39180982]\n",
      " [0.5129119  0.68290687 0.6594999 ]\n",
      " [0.04567504 0.28698313 0.6117815 ]\n",
      " [0.14929497 0.36755717 0.5202992 ]\n",
      " [0.47959077 0.8417324  0.27873743]], shape=(5, 3), dtype=float32)\n",
      "\n",
      "Тензор весов:\n",
      "tf.Tensor(\n",
      "[[0.64196765 0.6231067  0.1494534  0.29552937 0.14258552 0.41521358\n",
      "  0.75516474 0.12704074 0.6554433  0.8640796 ]\n",
      " [0.01536858 0.39732957 0.51612926 0.5122229  0.1909318  0.4733852\n",
      "  0.32382703 0.7558397  0.87336016 0.756505  ]\n",
      " [0.8965746  0.6000954  0.6159599  0.8604013  0.33750594 0.54090583\n",
      "  0.30035603 0.68966794 0.78704774 0.88780725]], shape=(3, 10), dtype=float32)\n",
      "\n",
      "Выход после симуляции:\n",
      "[[0.64858615 0.85431004 0.75368792 0.91071045 0.36039293 0.80490053\n",
      "  0.73174483 0.9798981  1.35342693 1.38417876]\n",
      " [0.931059   0.98670077 0.83535016 1.06881559 0.42610759 0.8929733\n",
      "  0.80656147 1.03616476 1.45166612 1.5453279 ]\n",
      " [0.58224016 0.50961453 0.53177953 0.68687522 0.26778668 0.48573464\n",
      "  0.31117731 0.64464194 0.76207829 0.7997151 ]\n",
      " [0.56797844 0.55129719 0.53250313 0.68005836 0.2670697  0.51741827\n",
      "  0.38804224 0.6556145  0.82836449 0.86898696]\n",
      " [0.57072687 0.80055046 0.67781025 0.81271374 0.32317171 0.74836695\n",
      "  0.71846616 0.88937855 1.26885974 1.29864454]]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:52:09.659807Z",
     "start_time": "2024-11-04T15:52:09.640077Z"
    }
   },
   "cell_type": "code",
   "source": "modelll = create_model()",
   "id": "f6afc8e9aef3b39c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_11\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_23 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m4\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m4\u001B[0m (16.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (16.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m4\u001B[0m (16.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (16.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:52:15.567514Z",
     "start_time": "2024-11-04T15:52:15.250848Z"
    }
   },
   "cell_type": "code",
   "source": "create_error_report(modelll)",
   "id": "952390a2672ac914",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_bin.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[74], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m create_error_report(modelll)\n",
      "Cell \u001B[1;32mIn[71], line 2\u001B[0m, in \u001B[0;36mcreate_error_report\u001B[1;34m(model_report, val_split)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_error_report\u001B[39m(model_report: Sequential, val_split: \u001B[38;5;28mfloat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     data: pd\u001B[38;5;241m.\u001B[39mDataFrame \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/data_bin.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m     X \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      4\u001B[0m     y \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[0;32m   1662\u001B[0m     f,\n\u001B[0;32m   1663\u001B[0m     mode,\n\u001B[0;32m   1664\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1665\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1666\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m   1667\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[0;32m   1668\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1669\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1670\u001B[0m )\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    860\u001B[0m             handle,\n\u001B[0;32m    861\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    862\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    863\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    864\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    865\u001B[0m         )\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/data_bin.csv'"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:48:22.464873Z",
     "start_time": "2024-11-04T15:48:22.459916Z"
    }
   },
   "cell_type": "code",
   "source": "modelll.get_layer('dense_22').get_weights()",
   "id": "abb3514295e76057",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.8884676 ],\n",
       "        [-0.27454597],\n",
       "        [ 0.67404944]], dtype=float32),\n",
       " array([-0.09875816], dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:32:42.111518Z",
     "start_time": "2024-11-04T15:32:42.105871Z"
    }
   },
   "cell_type": "code",
   "source": "modelll.get_layer('dense_18').get_weights()",
   "id": "3aecdf46c88c0884",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.79077834, -0.42251903, -0.30026877, -0.14033717, -0.37014264],\n",
       "        [-0.33898225, -0.13823019,  0.13702184, -0.1441328 ,  0.22989969],\n",
       "        [ 0.8821523 ,  0.78911585,  0.472924  , -0.5663092 , -0.3922982 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.10029585,  0.11535221,  0.08029889,  0.        , -0.09838567],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:04:49.304170Z",
     "start_time": "2024-11-04T15:04:49.300936Z"
    }
   },
   "cell_type": "code",
   "source": "X, y = generate_dataset(size=5)",
   "id": "3bd97cfadcb78658",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:04:52.780702Z",
     "start_time": "2024-11-04T15:04:52.776642Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "f2890cbdd419821b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T15:05:04.547446Z",
     "start_time": "2024-11-04T15:05:04.543819Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "f9ed5a20952cf240",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1bab0599e744281"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
